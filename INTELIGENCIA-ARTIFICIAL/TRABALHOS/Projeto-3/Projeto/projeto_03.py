# -*- coding: utf-8 -*-
"""Projeto 03.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HBkFZqz61isElsvw3X-yBa8cL7MnpcC0

#Projeto 03 de Inteligência Artificial


Universidade Federal do Sul e Sudeste do Pará 

Faculdade de Computação e Engenharia Elétrica 

Inteligência Artificial – Prof. Dr. Elton Alves 

Projeto 3 – Redes Neurais Artificiais 
 
### Objetivo: 
- Desenvolver uma aplicação prática de emprego de RNA MLP (SEM CLONAGEM – 
IDEIA INOVADORA). 

### Critérios: 
- Deve ser realizado em equipes (no máximo três membros), utilizando uma ferramenta de sua preferência. 
- O trabalho deve aplicar um método de normalização para os dados de entrada. 
- O trabalho deve utilizar uma técnica de validação cruzad (generalização da RNA). 
- Escolher uma métrica para mostrar o desempenho da RNA. 
- Encontrar a melhor topologia para a solução do problema. 
- Nota = 4 pts. 
- Data da entrega e apresentação: 03/05/2022. 
▪ Critérios avaliativos 
✔ Relevância da proposta (0,5 pt). 
✔ Escrita científica (0,5 pt) 
✔ Artigo template IEEE: 3-4 páginas (0,5 pt). 
✔ Descrever de forma clara e objetiva a metodologia adotada, 
referencial  teórico,  conclusões  e  referências  bibliográficas  (0,5 
pts). 
✔ Resultados obtidos com o RNA (2 pt)

Metodologia do script

- Primeiro inicializamos a função de RNA-MLP disponível na biblioteca sklearn

- Segundo Iincializamos os arrays e carregamos os dados de dataset
- Para isso foi utilizado um dataset encontrado no site: https://archive.ics.uci.edu/ml/datasets/Letter+Recognition

Data Set Characteristics:  


- Para aplicarmos a técnica de validação cruzada foi separado as 20.000 (20 mil linhas X 16 colunas de entrada X 1 coluna de saída) de amostra de dados em conjuntos de mini datasets com 2000 linhas totalizando 10 datasets com isso podemos treinar a rede neural de 10 formas diferentes e testar com 2000 amostras de outros datasets. Com isso gera-se um relatório sobre o nível de generalização da rede neural.

- Para métricas de desempenho podemos escolher 13 letras (metade do alfabeto completo) e verificar o desempenho delas utilizando as técnicas de validação cruzada.

- A partir dos resultados iremos ajustar os parâmetros da rede realizando novos testes e verificando qual topologia (modelo ou configuração) possui expressivamente o melhor resultado.

## Conceitos importantes

### Generalização

- Habilidade para realizar predições para padrões de entrada que não fazem parte dos padrões utilizados para treinamento, mas que foram gerados da mesma distribuição entrada/saída que estes.
- Considerada uma das maiores vantagens da rede neural.
- Pobre generalização ( sub-treinamento e sobre-treinamento)

### Pobre generalização:
- Underfitting (sub-treinamento) complexidade da rede neural é inferior a complexidade do fenômeno que está sendo modelado. 
 - O modelo tem um alto valor de bias.
- Overfitting (sobre-treinamento) complexidade da rede neural é maior que a complexidade do fenômeno que está sendo modelado.
 - O modelo tem um valor alto de variância.

### Técnica para evitar o overfitting

#### Validação Cruzada (Parada antecipada)
- Dados divididos em três grupos: treino, validação e teste.
- Grande número de dados disponível.
- Conjunto de validação 
  - Usado para testar a generalização da rede durante o treinamento.
  - Se erro de validação aumenta, isto pode indicar sobre-treino e o treinamento deve ser então finalizado.

## Inicializando bibliotecas
"""

from sklearn.neural_network import MLPClassifier
# from google.colab import drive

"""## Inicializando arrays"""

inputs = []
outputs = []
letter_outputs = []
inputs.append([])
outputs.append([])
letter_outputs.append([])

# drive.mount('/content/drive/')

"""## Processamento de Dados"""

letter_recognition = open("/home/mestrezen/Documents/graduacao/Per-odo-8-facul/INTELIGENCIA-ARTIFICIAL/TRABALHOS/Projeto-3/Projeto/dataset/letter-recognition.data", "r")
letter_recognition = letter_recognition.readlines()
letter_convert = open("/home/mestrezen/Documents/graduacao/Per-odo-8-facul/INTELIGENCIA-ARTIFICIAL/TRABALHOS/Projeto-3/Projeto/dataset/letter-convert.data", "r")
letter_convert = letter_convert.readlines()
# 16 parametros inputs
# 1 parametro saida
dataset_separator = 0
indicates_next_dataset = 0
for letter_recognition_line in letter_recognition:
    letter_recognition_line = letter_recognition_line.replace("\n", "").split(",")
    if dataset_separator < 2000:
        inputs[indicates_next_dataset].append(list(map(int, letter_recognition_line[1:15])))
        
        for letter_convert_line in letter_convert:
            letter_convert_line = letter_convert_line.replace("\n", "").split(",")
            if letter_convert_line[0] == letter_recognition_line[0]:
                outputs[indicates_next_dataset].append([int(letter_convert_line[1])])
                letter_outputs[indicates_next_dataset].append([letter_convert_line[0]])
                break    
        dataset_separator +=1
    else:
        inputs.append([])
        outputs.append([])
        letter_outputs.append([])
        dataset_separator = 0
        indicates_next_dataset += 1

"""## Resultado do Processamento"""

# print('inputs: ' + str(inputs) + '\n' + 'numero inputs' + str(len(inputs)) + '\n'+ 'outputs: ' + str(outputs) + '\n' + 'numero outputs' + str(len(outputs)))
print("\n")
# print(outputs)
print('inputs[0]: ' + str(inputs[0]) + '\n' + 'numero inputs[0]: ' + str(len(inputs[0])) + '\n'+ 'outputs[0]: ' + str(outputs[0]) + '\n' + 'numero outputs[0]: ' + str(len(outputs[0])))

"""## Etapa de Treino e Validação"""

redeNeural = MLPClassifier(verbose=(True), 
                           max_iter=1000,
                           tol=0.001,
                           activation='logistic',
                           learning_rate_init=0.1,
                           solver='sgd') #cria a RNA
#verbose mostra o erro gerado pela RNA
#max_iter é o número máximo de épocas
#tol é a tolerância
# activation é a função de ativação
#learning_rate_init=0.3 é a taxa de aprendizagem
#Solver é o algoritmo utilizado para atualização dos pesos
redeNeural.fit(inputs[0], outputs[0]) #Treinamento da RNA

"""## Etapa de Teste"""

hits = 0 #erros
hits_all = 0
misses = 0 #acertos
misses_all = 0
for input_list_number in range(len(inputs)):
    if input_list_number > 0:
        for input_number in range(len(inputs[input_list_number])):
            output_predict = redeNeural.predict([inputs[input_list_number][input_number]]) #fazer a previsão

            for letter_convert_line in letter_convert:
                letter_convert_line = letter_convert_line.split(",")
                if int(letter_convert_line[1]) == int(output_predict[0]):
                    output_predict = letter_convert_line[0]
                    break 
            if str(letter_outputs[input_list_number][input_number][0]) == str(output_predict):
                hits +=1
            else:
                misses += 1
        print("\n==========")
        print("Total analisado no conjunto: "+ str(hits + misses))
        print("Resultado conjunto " + str(input_list_number) + ": " + str(hits) + " acertos e " + str(misses) + " erros")
        porcentage_hits = (hits/len(inputs[input_list_number]))*100
        porcentage_misses = (misses/len(inputs[input_list_number]))*100
        print("Porcentagem de acertos: " + str(porcentage_hits) + "%" + "\nPorcentagem de erros: " + str(porcentage_misses) + "%")
        print("==========")
        hits_all += hits
        misses_all += misses
        hits = 0
        misses = 0

print("\n==========")
print("Total analisado: "+ str(hits_all + misses_all))
print("Resultado geral: " + str(hits_all) + " acertos e " + str(misses_all) + " erros")
porcentage_hits = (hits_all/len(inputs))*100
porcentage_misses = (misses_all/len(inputs))*100
print("Porcentagem de acertos: " + str(porcentage_hits) + "%" + "\nPorcentagem de erros: " + str(porcentage_misses) + "%")
print("==========\n")